{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import azureml.core\n",
        "\n",
        "# Check core SDK version number.\n",
        "print('SDK version:', azureml.core.VERSION)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "SDK version: 1.34.0\n"
        }
      ],
      "execution_count": 1,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import azureml.core\n",
        "from azureml.core import Workspace\n",
        "\n",
        "# Load the workspace from the saved config file\n",
        "ws = Workspace.from_config()\n",
        "print('Ready to use Azure ML {} to work with {}'.format(azureml.core.VERSION, ws.name))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Ready to use Azure ML 1.34.0 to work with aml-walkthrough-ws\n"
        }
      ],
      "execution_count": 2,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#load the dependencies\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn import metrics\n",
        "import matplotlib.pyplot as plt \n",
        "from matplotlib import style\n",
        "plt.style.use( 'bmh')"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_DIR = \"./data\"\n",
        "data_df = pd.read_csv(os.path.join(DATA_DIR, 'stock_data.csv'))\n",
        "print(data_df.shape)\n",
        "data_df.head()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "(1949, 7)\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 4,
          "data": {
            "text/plain": "                    Datetime        Open        High         Low       Close  \\\n0  2022-08-01 09:30:00-04:00  277.820007  277.939911  277.070007  277.679993   \n1  2022-08-01 09:31:00-04:00  277.589996  277.649994  276.743103  277.279999   \n2  2022-08-01 09:32:00-04:00  277.339996  277.665009  277.220093  277.470001   \n3  2022-08-01 09:33:00-04:00  277.440002  278.250000  277.261414  278.000000   \n4  2022-08-01 09:34:00-04:00  277.500000  277.739990  277.436707  277.640015   \n\n    Adj Close  Volume  \n0  277.679993  731044  \n1  277.279999  185477  \n2  277.470001  100953  \n3  278.000000  112216  \n4  277.640015  106432  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Datetime</th>\n      <th>Open</th>\n      <th>High</th>\n      <th>Low</th>\n      <th>Close</th>\n      <th>Adj Close</th>\n      <th>Volume</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2022-08-01 09:30:00-04:00</td>\n      <td>277.820007</td>\n      <td>277.939911</td>\n      <td>277.070007</td>\n      <td>277.679993</td>\n      <td>277.679993</td>\n      <td>731044</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2022-08-01 09:31:00-04:00</td>\n      <td>277.589996</td>\n      <td>277.649994</td>\n      <td>276.743103</td>\n      <td>277.279999</td>\n      <td>277.279999</td>\n      <td>185477</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2022-08-01 09:32:00-04:00</td>\n      <td>277.339996</td>\n      <td>277.665009</td>\n      <td>277.220093</td>\n      <td>277.470001</td>\n      <td>277.470001</td>\n      <td>100953</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2022-08-01 09:33:00-04:00</td>\n      <td>277.440002</td>\n      <td>278.250000</td>\n      <td>277.261414</td>\n      <td>278.000000</td>\n      <td>278.000000</td>\n      <td>112216</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2022-08-01 09:34:00-04:00</td>\n      <td>277.500000</td>\n      <td>277.739990</td>\n      <td>277.436707</td>\n      <td>277.640015</td>\n      <td>277.640015</td>\n      <td>106432</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 4,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import os, shutil\n",
        "\n",
        "# Create a folder for the experiment files\n",
        "training_folder = 'stock-prediction-training'\n",
        "os.makedirs(training_folder, exist_ok=True)\n",
        "\n",
        "# Copy the data file into the experiment folder\n",
        "shutil.copy('data/stock_data.csv', os.path.join(training_folder, \"stock_data.csv\"))"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 5,
          "data": {
            "text/plain": "'stock-prediction-training/stock_data.csv'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 5,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile $training_folder/stock_training.py\n",
        "# Import libraries\n",
        "from azureml.core import Run\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import roc_curve\n",
        "\n",
        "# Get the experiment run context\n",
        "run = Run.get_context()\n",
        "\n",
        "# load the diabetes dataset\n",
        "print(\"Loading Data...\")\n",
        "stock_data = pd.read_csv('stock_data.csv')\n",
        "\n",
        "x= stock_data[['Open','High','Low']].values\n",
        "y= stock_data[['Close']].values\n",
        "\n",
        "x_train,x_test,y_train,y_test= train_test_split(x,y,test_size=0.2,random_state=0)\n",
        "\n",
        "model= LinearRegression()\n",
        "model.fit(x_train,y_train)\n",
        "\n",
        "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)\n",
        "\n",
        "# y_pred= model.predict(x_test)\n",
        "\n",
        "# calculate accuracy\n",
        "y_hat= model.predict(x_test)\n",
        "acc = np.average(y_hat == y_test)\n",
        "print('Accuracy:', acc)\n",
        "run.log('Accuracy', np.float(acc))\n",
        "\n",
        "# # calculate AUC\n",
        "# y_scores = model.predict_proba(x_test)\n",
        "# auc = roc_auc_score(y_test,y_scores[:,1])\n",
        "# print('AUC: ' + str(auc))\n",
        "# run.log('AUC', np.float(auc))\n",
        "\n",
        "# Save the trained model in the outputs folder\n",
        "os.makedirs('outputs', exist_ok=True)\n",
        "joblib.dump(value=model, filename='outputs/stock_model.pkl')\n",
        "\n",
        "run.complete()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting stock-prediction-training/stock_training.py\n"
        }
      ],
      "execution_count": 6,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile $training_folder/conda_dependencies.yml\r\n",
        "name: scikit-learn-env\r\n",
        "channels:\r\n",
        "    - defaults\r\n",
        "dependencies:\r\n",
        "  - python=3.6.2\r\n",
        "  - pip\r\n",
        "  - pip:\r\n",
        "    - azureml-defaults\r\n",
        "    - azureml-widgets\r\n",
        "    - azureml-sdk\r\n",
        "    - joblib\r\n",
        "    - lightgbm\r\n",
        "    - inference-schema[numpy-support]\r\n",
        "    - imblearn\r\n",
        "    - imbalanced-learn\r\n",
        "  - numpy\r\n",
        "  - pandas\r\n",
        "  - scikit-learn"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting stock-prediction-training/conda_dependencies.yml\n"
        }
      ],
      "execution_count": 7,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile $experiment_folder/conda_dependencies.yml\r\n",
        "name: scikit-learn-env\r\n",
        "channels:\r\n",
        "    - defaults\r\n",
        "dependencies:\r\n",
        "  - python=3.6.2\r\n",
        "  - pip\r\n",
        "  - pip:\r\n",
        "    - azureml-defaults\r\n",
        "    - azureml-widgets\r\n",
        "    - azureml-sdk\r\n",
        "    - joblib\r\n",
        "    - lightgbm\r\n",
        "    - inference-schema[numpy-support]\r\n",
        "    - imblearn\r\n",
        "    - imbalanced-learn\r\n",
        "  - numpy\r\n",
        "  - pandas\r\n",
        "  - scikit-learn"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Experiment, ScriptRunConfig\n",
        "from azureml.widgets import RunDetails\n",
        "from azureml.core import Environment\n",
        "# env = Environment.get(workspace=ws, name=\"AzureML-sklearn-0.24.1-ubuntu18.04-py37-cpu-inference\")\"\n",
        "# env = Environment.get(workspace=ws, name=\"AzureML-sklearn-1.0-ubuntu20.04-py38-cpu\")\n",
        "sklearn_env = Environment.from_conda_specification(name='stock-predict-env', file_path=os.path.join(training_folder,'conda_dependencies.yml'))\n",
        "\n",
        "script_config = ScriptRunConfig(source_directory=training_folder,\n",
        "                      script='stock_training.py',\n",
        "                      arguments=['--kernel', 'linear', '--penalty'],\n",
        "                      environment=sklearn_env)"
      ],
      "outputs": [],
      "execution_count": 8,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Experiment, ScriptRunConfig\n",
        "from azureml.core import Environment\n",
        "\n",
        "# submit the experiment\n",
        "experiment = Experiment(workspace = ws, name = 'stock-prediction-experiment-hack')\n",
        "run = experiment.submit(config=script_config)"
      ],
      "outputs": [],
      "execution_count": 9,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# Shows output of the run on stdout.\n",
        "run.wait_for_completion(show_output=True)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "RunId: stock-prediction-experiment-hack_1660757346_dc168c8d\nWeb View: https://ml.azure.com/runs/stock-prediction-experiment-hack_1660757346_dc168c8d?wsid=/subscriptions/b30d9dbd-c0f7-405f-902c-3eabd080eb00/resourcegroups/aml-walkthrough-rg/workspaces/aml-walkthrough-ws&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\n\nStreaming azureml-logs/70_driver_log.txt\n========================================\n\n[2022-08-17T17:29:09.886419] Entering context manager injector.\n/home/azureuser/.azureml/envs/azureml_65baac26419658cafa53b1a04103f5a6/lib/python3.6/site-packages/paramiko/transport.py:33: CryptographyDeprecationWarning: Python 3.6 is no longer supported by the Python core team. Therefore, support for it is deprecated in cryptography and will be removed in a future release.\n  from cryptography.hazmat.backends import default_backend\n[2022-08-17T17:29:10.670870] context_manager_injector.py Command line Options: Namespace(inject=['ProjectPythonPath:context_managers.ProjectPythonPath', 'RunHistory:context_managers.RunHistory', 'TrackUserError:context_managers.TrackUserError', 'UserExceptions:context_managers.UserExceptions'], invocation=['stock_training.py', '--kernel', 'linear', '--penalty'])\nScript type = None\n[2022-08-17T17:29:10.675829] Entering Run History Context Manager.\n[2022-08-17T17:29:12.286242] Current directory: /tmp/azureml_runs/stock-prediction-experiment-hack_1660757346_dc168c8d\n[2022-08-17T17:29:12.286622] Preparing to call script [stock_training.py] with arguments:['--kernel', 'linear', '--penalty']\n[2022-08-17T17:29:12.287094] After variable expansion, calling script [stock_training.py] with arguments:['--kernel', 'linear', '--penalty']\n\nLoading Data...\nAccuracy: 0.0\n\n\n[2022-08-17T17:29:18.547212] The experiment completed successfully. Finalizing run...\n[2022-08-17T17:29:18.547251] Start FinalizingInRunHistory\n[2022-08-17T17:29:18.555093] Logging experiment finalizing status in history service.\nStarting the daemon thread to refresh tokens in background for process with pid = 12908\nCleaning up all outstanding Run operations, waiting 300.0 seconds\n3 items cleaning up...\nCleanup took 0.16837000846862793 seconds\n[2022-08-17T17:29:19.690994] Finished context manager injector.\n\nExecution Summary\n=================\nRunId: stock-prediction-experiment-hack_1660757346_dc168c8d\nWeb View: https://ml.azure.com/runs/stock-prediction-experiment-hack_1660757346_dc168c8d?wsid=/subscriptions/b30d9dbd-c0f7-405f-902c-3eabd080eb00/resourcegroups/aml-walkthrough-rg/workspaces/aml-walkthrough-ws&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\n\nCPU times: user 197 ms, sys: 11.7 ms, total: 209 ms\nWall time: 8.85 s\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 10,
          "data": {
            "text/plain": "{'runId': 'stock-prediction-experiment-hack_1660757346_dc168c8d',\n 'target': 'local',\n 'status': 'Completed',\n 'startTimeUtc': '2022-08-17T17:29:08.78345Z',\n 'endTimeUtc': '2022-08-17T17:29:22.514034Z',\n 'services': {},\n 'properties': {'_azureml.ComputeTargetType': 'local',\n  'ContentSnapshotId': 'cbf86181-729a-43a9-bdf7-2c9413281637'},\n 'inputDatasets': [],\n 'outputDatasets': [],\n 'runDefinition': {'script': 'stock_training.py',\n  'command': '',\n  'useAbsolutePath': False,\n  'arguments': ['--kernel', 'linear', '--penalty'],\n  'sourceDirectoryDataStore': None,\n  'framework': 'Python',\n  'communicator': 'None',\n  'target': 'local',\n  'dataReferences': {},\n  'data': {},\n  'outputData': {},\n  'datacaches': [],\n  'jobName': None,\n  'maxRunDurationSeconds': 2592000,\n  'nodeCount': 1,\n  'instanceTypes': [],\n  'priority': None,\n  'credentialPassthrough': False,\n  'identity': None,\n  'environment': {'name': 'stock-predict-env',\n   'version': 'Autosave_2022-08-17T17:02:26Z_ff97a478',\n   'assetId': 'azureml://locations/westus2/workspaces/be972235-dac7-456b-bba5-5d39412d89e7/environments/stock-predict-env/versions/Autosave_2022-08-17T17:02:26Z_ff97a478',\n   'autoRebuild': True,\n   'python': {'interpreterPath': 'python',\n    'userManagedDependencies': False,\n    'condaDependencies': {'channels': ['defaults'],\n     'dependencies': ['python=3.6.2',\n      'pip',\n      {'pip': ['azureml-defaults',\n        'azureml-widgets',\n        'azureml-sdk',\n        'joblib',\n        'lightgbm',\n        'inference-schema[numpy-support]',\n        'imblearn',\n        'imbalanced-learn']},\n      'numpy',\n      'pandas',\n      'scikit-learn'],\n     'name': 'scikit-learn-env'},\n    'baseCondaEnvironment': None},\n   'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'},\n   'docker': {'baseImage': 'mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:20210806.v1',\n    'platform': {'os': 'Linux', 'architecture': 'amd64'},\n    'baseDockerfile': None,\n    'baseImageRegistry': {'address': None, 'username': None, 'password': None},\n    'enabled': False,\n    'arguments': []},\n   'spark': {'repositories': [], 'packages': [], 'precachePackages': True},\n   'inferencingStackVersion': None},\n  'history': {'outputCollection': True,\n   'directoriesToWatch': ['logs'],\n   'enableMLflowTracking': True,\n   'snapshotProject': True},\n  'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment',\n    'spark.yarn.maxAppAttempts': '1'}},\n  'parallelTask': {'maxRetriesPerWorker': 0,\n   'workerCountPerNode': 1,\n   'terminalExitCodes': None,\n   'configuration': {}},\n  'amlCompute': {'name': None,\n   'vmSize': None,\n   'retainCluster': False,\n   'clusterMaxNodeCount': None},\n  'aiSuperComputer': {'instanceType': 'D2',\n   'imageVersion': 'pytorch-1.7.0',\n   'location': None,\n   'aiSuperComputerStorageData': None,\n   'interactive': False,\n   'scalePolicy': None,\n   'virtualClusterArmId': None,\n   'tensorboardLogDirectory': None,\n   'sshPublicKey': None,\n   'sshPublicKeys': None,\n   'enableAzmlInt': True,\n   'priority': 'Medium',\n   'slaTier': 'Standard',\n   'userAlias': None},\n  'kubernetesCompute': {'instanceType': None},\n  'tensorflow': {'workerCount': 1, 'parameterServerCount': 1},\n  'mpi': {'processCountPerNode': 1},\n  'pyTorch': {'communicationBackend': 'nccl', 'processCount': None},\n  'hdi': {'yarnDeployMode': 'Cluster'},\n  'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5},\n  'exposedPorts': None,\n  'docker': {'useDocker': False,\n   'sharedVolumes': True,\n   'shmSize': '2g',\n   'arguments': []},\n  'cmk8sCompute': {'configuration': {}},\n  'commandReturnCodeConfig': {'returnCode': 'Zero',\n   'successfulReturnCodes': []},\n  'environmentVariables': {},\n  'applicationEndpoints': {},\n  'parameters': []},\n 'logFiles': {'azureml-logs/60_control_log.txt': 'https://amlwalktstorage1190e2c28.blob.core.windows.net/azureml/ExperimentRun/dcid.stock-prediction-experiment-hack_1660757346_dc168c8d/azureml-logs/60_control_log.txt?sv=2019-07-07&sr=b&sig=W4UeIdzDhOBIYM1ulijC%2FTtU8PPq%2FfKOlxDG0l6oXu0%3D&skoid=bc45a3fd-a957-4df1-b581-6f6c9a3544eb&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-08-17T16%3A52%3A38Z&ske=2022-08-19T01%3A02%3A38Z&sks=b&skv=2019-07-07&st=2022-08-17T17%3A19%3A23Z&se=2022-08-18T01%3A29%3A23Z&sp=r',\n  'azureml-logs/70_driver_log.txt': 'https://amlwalktstorage1190e2c28.blob.core.windows.net/azureml/ExperimentRun/dcid.stock-prediction-experiment-hack_1660757346_dc168c8d/azureml-logs/70_driver_log.txt?sv=2019-07-07&sr=b&sig=lrvVSRZt8QRDrGoDTLPXI0d5SJBa11eLr6JoSW7NoMk%3D&skoid=bc45a3fd-a957-4df1-b581-6f6c9a3544eb&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-08-17T16%3A52%3A38Z&ske=2022-08-19T01%3A02%3A38Z&sks=b&skv=2019-07-07&st=2022-08-17T17%3A19%3A23Z&se=2022-08-18T01%3A29%3A23Z&sp=r',\n  'logs/azureml/12908_azureml.log': 'https://amlwalktstorage1190e2c28.blob.core.windows.net/azureml/ExperimentRun/dcid.stock-prediction-experiment-hack_1660757346_dc168c8d/logs/azureml/12908_azureml.log?sv=2019-07-07&sr=b&sig=JuNosPDJu3TmSJ74l0imPIovR1O4PaCDebCmY0actB0%3D&skoid=bc45a3fd-a957-4df1-b581-6f6c9a3544eb&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-08-17T16%3A52%3A38Z&ske=2022-08-19T01%3A02%3A38Z&sks=b&skv=2019-07-07&st=2022-08-17T17%3A19%3A14Z&se=2022-08-18T01%3A29%3A14Z&sp=r'},\n 'submittedBy': 'Meer Alam'}"
          },
          "metadata": {}
        }
      ],
      "execution_count": 10,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Model\r\n",
        "\r\n",
        "# Register the model\r\n",
        "run.register_model(model_path='outputs/stock_model.pkl', model_name='stock_model',\r\n",
        "                   tags={'Training context':'ScriptRunConfig'},\r\n",
        "                   properties={'Accuracy': run.get_metrics()['Accuracy']})"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 11,
          "data": {
            "text/plain": "Model(workspace=Workspace.create(name='aml-walkthrough-ws', subscription_id='b30d9dbd-c0f7-405f-902c-3eabd080eb00', resource_group='aml-walkthrough-rg'), name=stock_model, id=stock_model:3, version=3, tags={'Training context': 'ScriptRunConfig'}, properties={'Accuracy': '0.0'})"
          },
          "metadata": {}
        }
      ],
      "execution_count": 11,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Model\r\n",
        "\r\n",
        "for model in Model.list(ws):\r\n",
        "    print(model.name, 'version:', model.version)\r\n",
        "    for tag_name in model.tags:\r\n",
        "        tag = model.tags[tag_name]\r\n",
        "        print ('\\t',tag_name, ':', tag)\r\n",
        "    for prop_name in model.properties:\r\n",
        "        prop = model.properties[prop_name]\r\n",
        "        print ('\\t',prop_name, ':', prop)\r\n",
        "    print('\\n')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "stock_model version: 3\n\t Training context : ScriptRunConfig\n\t Accuracy : 0.0\n\n\nstock_model version: 2\n\t Training context : ScriptRunConfig\n\t Accuracy : 0.0\n\n\nAutoML16dd11da30 version: 1\n\n\ndiabetes_model version: 12\n\t Training context : Pipeline\n\n\ndiabetes_model version: 11\n\t Training context : Pipeline\n\n\namlstudio-realtimestockpred version: 1\n\t CreatedByAMLStudio : true\n\n\namlstudio-stockpricepredictor version: 1\n\t CreatedByAMLStudio : true\n\n\nstock_model version: 1\n\t Training context : ScriptRunConfig\n\t Accuracy : 0.0\n\n\nAutoML703a6658842 version: 1\n\n\ncredit_defaults_model version: 10\n\t flavors.python_function : {\n  \"model_path\": \"model.pkl\",\n  \"loader_module\": \"mlflow.sklearn\",\n  \"python_version\": \"3.7.11\",\n  \"env\": \"conda.yaml\"\n}\n\t flavors.sklearn : {\n  \"pickled_model\": \"model.pkl\",\n  \"sklearn_version\": \"0.24.1\",\n  \"serialization_format\": \"cloudpickle\"\n}\n\t flavors : python_function,sklearn\n\t azureml.artifactPrefix : ExperimentRun/dcid.536455f9-8445-4b07-9466-6af120a5f0a4/credit_defaults_model\n\t model_json : {\"run_id\": \"536455f9-8445-4b07-9466-6af120a5f0a4\", \"artifact_path\": \"credit_defaults_model\", \"utc_time_created\": \"2022-05-27 15:36:37.228539\", \"flavors\": {\"python_function\": {\"model_path\": \"model.pkl\", \"loader_module\": \"mlflow.sklearn\", \"python_version\": \"3.7.11\", \"env\": \"conda.yaml\"}, \"sklearn\": {\"pickled_model\": \"model.pkl\", \"sklearn_version\": \"0.24.1\", \"serialization_format\": \"cloudpickle\"}}, \"model_uuid\": \"8b1f798c9cbd49649991b754f75635ff\"}\n\t mlflow.modelSourceUri : azureml://experiments/e2e_registered_components/runs/536455f9-8445-4b07-9466-6af120a5f0a4/artifacts/credit_defaults_model\n\n\ncredit_defaults_model version: 9\n\t type : sklearn.GradientBoostingClassifier\n\n\ncredit_defaults_model version: 8\n\t type : sklearn.GradientBoostingClassifier\n\n\ncredit_defaults_model version: 7\n\t type : sklearn.GradientBoostingClassifier\n\n\narima_model.pkl version: 5\n\t area : robberies\n\t type : forecasting\n\t run_id : arima-mlops-localrun_1653417112_1a764fe7\n\n\narima_model.pkl version: 4\n\t area : robberies\n\t type : forecasting\n\t run_id : arima-mlops-localrun_1652389768_5d04d039\n\n\narima_model.pkl version: 3\n\t area : robberies\n\t type : forecasting\n\t run_id : arima-mlops-localrun_1652389054_1dad4251\n\n\narima_model.pkl version: 2\n\t area : robberies\n\t type : forecasting\n\t run_id : arima-mlops-localrun_1652388597_83f0490d\n\n\ncredit_defaults_model version: 6\n\t type : sklearn.GradientBoostingClassifier\n\n\ncredit_defaults_model version: 5\n\t type : sklearn.GradientBoostingClassifier\n\n\ncredit_defaults_model version: 4\n\t type : sklearn.GradientBoostingClassifier\n\n\ncredit_defaults_model version: 3\n\t type : sklearn.GradientBoostingClassifier\n\n\narima_model.pkl version: 1\n\t area : robberies\n\t type : forecasting\n\t run_id : arima-mlops-localrun_1651976069_190ab21e\n\n\ncredit_defaults_model version: 2\n\t type : sklearn.GradientBoostingClassifier\n\n\ncoco_model_person_full version: 2\n\t flavors.pytorch : {\n  \"model_data\": \"data\",\n  \"pytorch_version\": \"1.10.0\"\n}\n\t flavors.python_function : {\n  \"pickle_module_name\": \"mlflow.pytorch.pickle_module\",\n  \"loader_module\": \"mlflow.pytorch\",\n  \"python_version\": \"3.8.5\",\n  \"data\": \"data\",\n  \"env\": \"conda.yaml\"\n}\n\t flavors : pytorch,python_function\n\t azureml.artifactPrefix : ExperimentRun/dcid.08717a61-7bb6-4129-8661-95b3ee7ec2e4/final_model\n\t model_json : {\"run_id\": \"08717a61-7bb6-4129-8661-95b3ee7ec2e4\", \"artifact_path\": \"final_model\", \"utc_time_created\": \"2022-04-25 19:42:45.388825\", \"flavors\": {\"pytorch\": {\"model_data\": \"data\", \"pytorch_version\": \"1.10.0\"}, \"python_function\": {\"pickle_module_name\": \"mlflow.pytorch.pickle_module\", \"loader_module\": \"mlflow.pytorch\", \"python_version\": \"3.8.5\", \"data\": \"data\", \"env\": \"conda.yaml\"}}, \"model_uuid\": \"5dba439ef3c14ec5a7413414b3cc73ad\"}\n\t mlflow.modelSourceUri : azureml://experiments/e2e_image_sample/runs/08717a61-7bb6-4129-8661-95b3ee7ec2e4/artifacts/final_model\n\n\ncoco_model_person_dev version: 2\n\t flavors.pytorch : {\n  \"model_data\": \"data\",\n  \"pytorch_version\": \"1.10.0\"\n}\n\t flavors.python_function : {\n  \"pickle_module_name\": \"mlflow.pytorch.pickle_module\",\n  \"loader_module\": \"mlflow.pytorch\",\n  \"python_version\": \"3.8.5\",\n  \"data\": \"data\",\n  \"env\": \"conda.yaml\"\n}\n\t flavors : pytorch,python_function\n\t azureml.artifactPrefix : ExperimentRun/dcid.0822482e-8748-414a-b6a3-af1dfa7065c5/final_model\n\t model_json : {\"run_id\": \"0822482e-8748-414a-b6a3-af1dfa7065c5\", \"artifact_path\": \"final_model\", \"utc_time_created\": \"2022-04-25 17:41:04.852959\", \"flavors\": {\"pytorch\": {\"model_data\": \"data\", \"pytorch_version\": \"1.10.0\"}, \"python_function\": {\"pickle_module_name\": \"mlflow.pytorch.pickle_module\", \"loader_module\": \"mlflow.pytorch\", \"python_version\": \"3.8.5\", \"data\": \"data\", \"env\": \"conda.yaml\"}}, \"model_uuid\": \"efd911729acf49bba25235d7fab99443\"}\n\t mlflow.modelSourceUri : azureml://experiments/e2e_image_sample/runs/0822482e-8748-414a-b6a3-af1dfa7065c5/artifacts/final_model\n\n\ncoco_model_person_full version: 1\n\t flavors.pytorch : {\n  \"model_data\": \"data\",\n  \"pytorch_version\": \"1.10.0\"\n}\n\t flavors.python_function : {\n  \"pickle_module_name\": \"mlflow.pytorch.pickle_module\",\n  \"loader_module\": \"mlflow.pytorch\",\n  \"python_version\": \"3.8.5\",\n  \"data\": \"data\",\n  \"env\": \"conda.yaml\"\n}\n\t flavors : pytorch,python_function\n\t azureml.artifactPrefix : ExperimentRun/dcid.61dce776-ac7a-404a-8737-a86203ad0740/final_model\n\t model_json : {\"run_id\": \"61dce776-ac7a-404a-8737-a86203ad0740\", \"artifact_path\": \"final_model\", \"utc_time_created\": \"2022-04-25 04:04:59.548951\", \"flavors\": {\"pytorch\": {\"model_data\": \"data\", \"pytorch_version\": \"1.10.0\"}, \"python_function\": {\"pickle_module_name\": \"mlflow.pytorch.pickle_module\", \"loader_module\": \"mlflow.pytorch\", \"python_version\": \"3.8.5\", \"data\": \"data\", \"env\": \"conda.yaml\"}}, \"model_uuid\": \"dc46ad121c124d0491f20944d04089da\"}\n\t mlflow.modelSourceUri : azureml://experiments/e2e_image_sample/runs/61dce776-ac7a-404a-8737-a86203ad0740/artifacts/final_model\n\n\ncoco_model_person_dev version: 1\n\t flavors.pytorch : {\n  \"model_data\": \"data\",\n  \"pytorch_version\": \"1.10.0\"\n}\n\t flavors.python_function : {\n  \"pickle_module_name\": \"mlflow.pytorch.pickle_module\",\n  \"loader_module\": \"mlflow.pytorch\",\n  \"python_version\": \"3.8.5\",\n  \"data\": \"data\",\n  \"env\": \"conda.yaml\"\n}\n\t flavors : pytorch,python_function\n\t azureml.artifactPrefix : ExperimentRun/dcid.6669d1be-c1c4-4f5b-8998-7ff6d4157ea3/final_model\n\t model_json : {\"run_id\": \"6669d1be-c1c4-4f5b-8998-7ff6d4157ea3\", \"artifact_path\": \"final_model\", \"utc_time_created\": \"2022-04-24 15:32:39.960252\", \"flavors\": {\"pytorch\": {\"model_data\": \"data\", \"pytorch_version\": \"1.10.0\"}, \"python_function\": {\"pickle_module_name\": \"mlflow.pytorch.pickle_module\", \"loader_module\": \"mlflow.pytorch\", \"python_version\": \"3.8.5\", \"data\": \"data\", \"env\": \"conda.yaml\"}}, \"model_uuid\": \"17b4b398e230465e9db79f22efa3ee27\"}\n\t mlflow.modelSourceUri : azureml://experiments/e2e_image_sample/runs/6669d1be-c1c4-4f5b-8998-7ff6d4157ea3/artifacts/final_model\n\n\ncredit_defaults_model version: 1\n\t type : sklearn.GradientBoostingClassifier\n\n\nmy-sklearn-model version: 3\n\t area : diabetes\n\t type : regression\n\n\nAutoMLcf81b924764 version: 1\n\n\ndiabetes_model version: 10\n\t Training context : Pipeline\n\n\nmy-sklearn-model version: 2\n\t area : diabetes\n\t type : regression\n\n\nbidaf_onnx version: 1\n\n\nmy-sklearn-model version: 1\n\t area : diabetes\n\t type : regression\n\n\ndiabetes_model version: 9\n\t AUC : 0.874147967560575\n\t AUC : 0.874147967560575\n\t Accuracy : 0.8886666666666667\n\n\nsklearn_regression_model.pkl version: 1\n\t area : diabetes\n\t type : regression\n\n\ndiabetes_model version: 8\n\t Training context : ScriptRunConfig\n\t AUC : 0.8483377282451863\n\t Accuracy : 0.774\n\n\ndiabetes_model version: 7\n\t Training context : ScriptRunConfig\n\t AUC : 0.8483377282451863\n\t Accuracy : 0.774\n\n\ndiabetes_model version: 6\n\t Training context : Pipeline\n\n\ndiabetes_model version: 5\n\t Training context : ScriptRunConfig\n\t AUC : 0.8483377282451863\n\t Accuracy : 0.774\n\n\ndiabetes_model version: 4\n\t Training context : ScriptRunConfig\n\t AUC : 0.8483377282451863\n\t Accuracy : 0.774\n\n\ndiabetes_model version: 3\n\t Training context : Estimator\n\t AUC : 0.8483377282451863\n\t Accuracy : 0.774\n\n\ndiabetes_model version: 2\n\t Training context : Estimator\n\t AUC : 0.8483377282451863\n\t Accuracy : 0.774\n\n\ndiabetes_model version: 1\n\t Training context : Estimator\n\t AUC : 0.8483377282451863\n\t Accuracy : 0.774\n\n\nsklearn_regression_model version: 2\n\n\nsklearn_regression_model version: 1\n\n\n"
        }
      ],
      "execution_count": 12,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\r\n",
        "# load the diabetes dataset\r\n",
        "print(\"Loading Data...\")\r\n",
        "stock_data = pd.read_csv('stock-prediction-training/stock_data.csv')\r\n",
        "#Users/meeral/Realtime Stock Price Prediction/yahoofinance/stock-prediction-training\r\n",
        "\r\n",
        "x= stock_data[['Open','High','Low']].values\r\n",
        "y= stock_data[['Close']].values\r\n",
        "\r\n",
        "#print(x)\r\n",
        "\r\n",
        "x_train,x_test,y_train,y_test= train_test_split(x,y,test_size=0.2,random_state=0)\r\n",
        "\r\n",
        "\r\n",
        "# model_path = Model.get_model_path(model_name=\"stock_model\")\r\n",
        "model_obj = Model(ws, 'stock_model' )\r\n",
        "model_path = model_obj.download(exist_ok = True)\r\n",
        "model = joblib.load(model_path)\r\n",
        "\r\n",
        "# Example when the model is a file\r\n",
        "# model_path = os.path.join(os.getenv(''), 'stock_model')\r\n",
        "\r\n",
        "# Example when the model is a folder containing a file\r\n",
        "# file_path = os.path.join(os.getenv('AZUREML_MODEL_DIR'), 'my_model_folder', 'sklearn_regression_model.pkl')\r\n",
        "\r\n",
        "    #with open(model_path, 'rb') as file:\r\n",
        "    #    model = pickle.load(file)\r\n",
        "# model = joblib.load(model_path)\r\n",
        "\r\n",
        "print('x_test: ')\r\n",
        "print (x_test)\r\n",
        "\r\n",
        "y_pred= model.predict(x_test)\r\n",
        "result= pd.DataFrame({'Actual':y_test.flatten(),'Predicted':y_pred.flatten()})\r\n",
        "result.head(25)\r\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Loading Data...\n"
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator LinearRegression from version 0.24.2 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n  UserWarning)\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 45,
          "data": {
            "text/plain": "        Actual   Predicted\n0   278.489990  278.463653\n1   283.355408  283.365573\n2   282.640015  282.594862\n3   278.850006  278.930075\n4   277.967194  277.930056\n5   280.279999  280.310254\n6   282.693604  282.726585\n7   281.239990  281.288030\n8   282.519989  282.518176\n9   273.329987  273.260686\n10  277.529999  277.530602\n11  282.910004  282.865383\n12  279.890015  279.872940\n13  282.829987  282.773324\n14  282.190002  282.292219\n15  282.010010  282.058603\n16  277.244995  277.191966\n17  275.660004  275.678824\n18  281.549988  281.544472\n19  279.554993  279.430686\n20  278.760010  278.737944\n21  281.984985  281.983034\n22  282.720001  282.697988\n23  277.475006  277.340610\n24  278.309998  278.322516",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Actual</th>\n      <th>Predicted</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>278.489990</td>\n      <td>278.463653</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>283.355408</td>\n      <td>283.365573</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>282.640015</td>\n      <td>282.594862</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>278.850006</td>\n      <td>278.930075</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>277.967194</td>\n      <td>277.930056</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>280.279999</td>\n      <td>280.310254</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>282.693604</td>\n      <td>282.726585</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>281.239990</td>\n      <td>281.288030</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>282.519989</td>\n      <td>282.518176</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>273.329987</td>\n      <td>273.260686</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>277.529999</td>\n      <td>277.530602</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>282.910004</td>\n      <td>282.865383</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>279.890015</td>\n      <td>279.872940</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>282.829987</td>\n      <td>282.773324</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>282.190002</td>\n      <td>282.292219</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>282.010010</td>\n      <td>282.058603</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>277.244995</td>\n      <td>277.191966</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>275.660004</td>\n      <td>275.678824</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>281.549988</td>\n      <td>281.544472</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>279.554993</td>\n      <td>279.430686</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>278.760010</td>\n      <td>278.737944</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>281.984985</td>\n      <td>281.983034</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>282.720001</td>\n      <td>282.697988</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>277.475006</td>\n      <td>277.340610</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>278.309998</td>\n      <td>278.322516</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "x_test: \n[[278.42999268 278.48999023 278.42999268]\n [283.5        283.51998901 283.30999756]\n [282.60998535 282.66000366 282.54998779]\n ...\n [280.20999146 280.26000977 280.17001343]\n [282.92999268 283.         282.82998657]\n [276.65499878 276.66000366 276.42999268]]\n"
        }
      ],
      "execution_count": 45,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile $training_folder/score.py \r\n",
        "#$training_folder/score.py\r\n",
        "# %%writefile $script_file\r\n",
        "\r\n",
        "import numpy\r\n",
        "import joblib\r\n",
        "import os\r\n",
        "from azureml.core.model import Model\r\n",
        "import json\r\n",
        "import numpy as np\r\n",
        "import pickle\r\n",
        "from sklearn.linear_model import Ridge\r\n",
        "from azureml.core.model import Model\r\n",
        "from inference_schema.schema_decorators import input_schema, output_schema\r\n",
        "from inference_schema.parameter_types.numpy_parameter_type import NumpyParameterType\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "def init():\r\n",
        "    # load the model from file into a global object\r\n",
        "    global model   \r\n",
        "    model_path = Model.get_model_path(model_name=\"stock_model\")\r\n",
        "    #with open(model_path, 'rb') as file:\r\n",
        "    #    model = pickle.load(file)\r\n",
        "    model = joblib.load(model_path)\r\n",
        "\r\n",
        "input_sample = numpy.array([\r\n",
        "    [514.390015,515.630005,505.369995]\r\n",
        "    ,\r\n",
        "    [513.000000,517.979980,510.369995]])\r\n",
        "output_sample = numpy.array([[\r\n",
        "    510.820007],\r\n",
        "    [517.349976\r\n",
        "    ]])\r\n",
        "\r\n",
        "# Inference_schema generates a schema for your web service\r\n",
        "# It then creates an OpenAPI (Swagger) specification for the web service\r\n",
        "# at http://<scoring_base_url>/swagger.json\r\n",
        "@input_schema('data', NumpyParameterType(input_sample))\r\n",
        "@output_schema(NumpyParameterType(output_sample))\r\n",
        "\r\n",
        "def run(raw_data):\r\n",
        "    data = np.array(json.loads(raw_data)['data'])\r\n",
        "    # result = model.predict(data)\r\n",
        "    # Get a prediction from the model\r\n",
        "    predictions = model.predict(data)\r\n",
        "    return json.dumps(predictions)\r\n",
        "\r\n",
        "\r\n",
        "if __name__ == \"__main__\":\r\n",
        "    # Test scoring\r\n",
        "    init()\r\n",
        "    test_row = '{\"data\":[[514.390015,515.630005,505.369995],[513.000000,517.979980,510.369995]]}'\r\n",
        "    prediction = run(test_row)\r\n",
        "    print(\"Test result: \", prediction)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting stock-prediction-training/score.py\n"
        }
      ],
      "execution_count": 66,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile $training_folder/score.py\r\n",
        "import json\r\n",
        "import joblib\r\n",
        "import pickle\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import azureml.train.automl\r\n",
        "from azureml.core.model import Model\r\n",
        "\r\n",
        "from inference_schema.schema_decorators import input_schema, output_schema\r\n",
        "from inference_schema.parameter_types.standard_py_parameter_type import StandardPythonParameterType\r\n",
        "from inference_schema.parameter_types.numpy_parameter_type import NumpyParameterType\r\n",
        "from inference_schema.parameter_types.pandas_parameter_type import PandasParameterType\r\n",
        "\r\n",
        "\r\n",
        "# Called when the service is loaded\r\n",
        "def init():\r\n",
        "    global model\r\n",
        "    # Get the path to the deployed model file and load it\r\n",
        "    model_path = Model.get_model_path('stock_model')\r\n",
        "    model = joblib.load(model_path)\r\n",
        "\r\n",
        "# providing 3 sample inputs for schema generation\r\n",
        "numpy_sample_input = NumpyParameterType(np.array([[514.390015,515.630005,505.369995], [513.000000,517.979980,510.369995]],dtype='float64'))\r\n",
        "\r\n",
        "# This is a nested input sample, any item wrapped by `ParameterType` will be described by schema\r\n",
        "sample_input = StandardPythonParameterType({'data': numpy_sample_input})\r\n",
        "sample_output = StandardPythonParameterType([[509.12305715658124], [515.6020041775826]])\r\n",
        "outputs = StandardPythonParameterType({'Results':sample_output}) # 'Results' is case sensitive\r\n",
        "\r\n",
        "@input_schema('Inputs', sample_input) \r\n",
        "# 'Inputs' is case sensitive\r\n",
        "\r\n",
        "@output_schema(outputs)\r\n",
        "\r\n",
        "# Called when a request is received\r\n",
        "def run(Inputs):\r\n",
        "    # Get the input data as a numpy array\r\n",
        "    inputData = Inputs['data']\r\n",
        "    # data = np.array(json.loads(inputData)['data'])\r\n",
        "    # data = json.loads(inputData)\r\n",
        "    print(inputData)\r\n",
        "    # Get a prediction from the model\r\n",
        "    predictions = model.predict(inputData)\r\n",
        "    print(predictions)\r\n",
        "    # result= pd.DataFrame({'Actual':inputData.flatten(),'Predicted':predictions.flatten()})\r\n",
        "    return json.dumps(predictions.tolist())\r\n",
        "    "
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting stock-prediction-training/score.py\n"
        }
      ],
      "execution_count": 57,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Conda Dependency File\r\n",
        "env_file = os.path.join(training_folder,\"conda_dependencies.yml\")\r\n",
        "# Print the .yml file\r\n",
        "# with open(env_file,\"r\") as f:\r\n",
        "#    print(f.read())\r\n",
        "# Set path for scoring script\r\n",
        "script_file = os.path.join(training_folder,\"score.py\")"
      ],
      "outputs": [],
      "execution_count": 58,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.webservice import AciWebservice\r\n",
        "from azureml.core.model import InferenceConfig\r\n",
        "from inference_schema.schema_decorators import input_schema, output_schema\r\n",
        "from azureml.core.model import Model\r\n",
        "# Configure the scoring environment\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "inference_config = InferenceConfig(runtime= \"python\",\r\n",
        "                                   entry_script=script_file,\r\n",
        "                                   conda_file=env_file)\r\n",
        "\r\n",
        "deployment_config = AciWebservice.deploy_configuration(cpu_cores = 1, memory_gb = 1)\r\n",
        "\r\n",
        "service_name = \"predictstockclosingprice\"\r\n",
        "ws = Workspace.from_config()\r\n",
        "model = Model(ws,\"stock_model\")\r\n",
        "\r\n",
        "service = Model.deploy(ws, service_name, [model], inference_config, deployment_config)\r\n",
        "\r\n",
        "service.wait_for_deployment(True)\r\n",
        "print(service.state)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\nRunning\n2022-08-17 19:24:11+00:00 Creating Container Registry if not exists.\n2022-08-17 19:24:11+00:00 Use the existing image.\n2022-08-17 19:24:12+00:00 Submitting deployment to compute.\n2022-08-17 19:24:17+00:00 Checking the status of deployment predictstockclosingprice..\n2022-08-17 19:26:21+00:00 Checking the status of inference endpoint predictstockclosingprice.\nSucceeded\nACI service creation operation finished, operation \"Succeeded\"\nHealthy\n"
        }
      ],
      "execution_count": 59,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(service.state)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Healthy\n"
        }
      ],
      "execution_count": 28,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model_path = Model.get_model_path(model_name=\"stock_model\")\r\n",
        "model_obj = Model(ws, 'stock_model' )\r\n",
        "model_path = model_obj.download(exist_ok = True)\r\n",
        "model = joblib.load(model_path)\r\n",
        "\r\n",
        "predict = model.predict([[514.390015,515.630005,505.369995],[513.000000,517.979980,510.369995]])\r\n",
        "print (type(predict))\r\n",
        "predict.tolist()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "<class 'numpy.ndarray'>\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 52,
          "data": {
            "text/plain": "[[509.12305715658124], [515.6020041775826]]"
          },
          "metadata": {}
        }
      ],
      "execution_count": 52,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\r\n",
        "\r\n",
        "x_new = [[514.390015,515.630005,505.369995],[513.000000,517.979980,510.369995]]\r\n",
        "print ('Patients: {}'.format(x_new[0]))\r\n",
        "\r\n",
        "# Convert the array to a serializable list in a JSON document\r\n",
        "input_json = json.dumps({\"Inputs\": {\"data\": x_new}})\r\n",
        "\r\n",
        "# input_json = json.dumps({\r\n",
        "#   \"Inputs\": {\r\n",
        "#     \"data\": [\r\n",
        "#       [\r\n",
        "#         514.390015,\r\n",
        "#         515.630005,\r\n",
        "#         505.369995\r\n",
        "#       ],\r\n",
        "#       [\r\n",
        "#         513,\r\n",
        "#         517.97998,\r\n",
        "#         510.369995\r\n",
        "#       ]\r\n",
        "#     ]\r\n",
        "#   }\r\n",
        "# })\r\n",
        "\r\n",
        "# Call the web service, passing the input data (the web service will also accept the data in binary format)\r\n",
        "predictions = service.run(input_data = input_json)\r\n",
        "print(predictions)\r\n",
        "\r\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Patients: [514.390015, 515.630005, 505.369995]\n[[509.12305715658124], [515.6020041775826]]\n"
        }
      ],
      "execution_count": 61,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\r\n",
        "import json\r\n",
        "\r\n",
        "from pathlib import Path\r\n",
        "\r\n",
        "from collections import defaultdict\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "model_path = os.path.join(os.getenv('AZUREML_MODEL_DIR'), 'trained_model_outputs')\r\n",
        "schema_file_path = Path(model_path) / '_schema.json'\r\n",
        "with open(schema_file_path) as fp:\r\n",
        "    schema_data = json.load(fp)\r\n",
        "\r\n",
        "\r\n",
        "def init():\r\n",
        "    global model\r\n",
        "    model = ModelDirectory.load(model_path).model\r\n",
        "\r\n",
        "\r\n",
        "def run(data):\r\n",
        "    data = json.loads(data)\r\n",
        "    input_entry = defaultdict(list)\r\n",
        "    for row in data:\r\n",
        "        for key, val in row.items():\r\n",
        "            input_entry[key].append(decode_nan(val))\r\n",
        "\r\n",
        "    data_frame_directory = create_dfd_from_dict(input_entry, schema_data)\r\n",
        "    score_module = ScoreModelModule()\r\n",
        "    result, = score_module.run(\r\n",
        "        learner=model,\r\n",
        "        test_data=DataTable.from_dfd(data_frame_directory),\r\n",
        "        append_or_result_only=True)\r\n",
        "    return json.dumps({\"result\": result.data_frame.values.tolist()})\r\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "kernel_info": {
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}